{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5084494",
   "metadata": {},
   "source": [
    "# Processing Example for AWS illustrating a simple Algorithm to Test Infrastucture\n",
    "\n",
    "This is based on using an environment simliar to the one that is created from the ASDI CMPI example: https://github.com/awslabs/amazon-asdi/tree/main/examples/cmip6 (this needs to run in us-east-1 , I think as the CMPI references failed from London)\n",
    "\n",
    "If you want to run this you may need to install some addtional libraries using ```conda install``` from a Terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import intake\n",
    "import boto3\n",
    "import botocore\n",
    "import datetime\n",
    "import s3fs\n",
    "import fsspec\n",
    "import dask\n",
    "#import sys\n",
    "import lz4\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from dask.distributed import performance_report, Client, progress, LocalCluster\n",
    "\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 18}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f90e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import boto3\n",
    "import os\n",
    "from boto3.dynamodb.conditions import Key, Attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some paramters for regridding\n",
    "regrid_lon=np.arange(0.0,360.0,0.1)\n",
    "regrid_lat=np.arange(-90.0,90.0,0.1)\n",
    "regrid_method='slinear'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51e0073",
   "metadata": {},
   "source": [
    "# Connect to Dask cluster scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e6bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from dask_worker_pools import pool, propagate_pools, visualize_pools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import lz4\n",
    "# Client.get_versions('self', check=True)\n",
    "client = Client('Dask-Scheduler.local-dask:8786')\n",
    "# client = Client('Dask-Scheduler.local-dask:8786',serializers=['dask', 'pickle'],\n",
    "#                deserializers=['dask', 'pickle']\n",
    "#               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf74138",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.scheduler_info()['workers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac38b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r activity_id\n",
    "%store -r variable_id\n",
    "%store -r table_id\n",
    "variable_ids = variable_id # tas is air temperature at 2m above surface\n",
    "table_id = table_id # Monthly data from Atmosphere - would really like this to be daily, but run out of memeory in client ('day' is the id)\n",
    "grid = 'gn' #\n",
    "\n",
    "# Records for Institution, experiment, and source_id are stored in https://github.com/WCRP-CMIP/CMIP6_CVs\n",
    "experiment_id = 'ssp245' #['ssp126', 'ssp245', 'ssp370', 'ssp585'] \n",
    "activity_ids = activity_id # Search Scenarios & CMIP activities only\n",
    "institution_id = 'MOHC' #just looking at our data in this example\n",
    "\n",
    "print(activity_id)\n",
    "print(variable_id)\n",
    "print(table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688daa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "my_region = session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e04920c",
   "metadata": {},
   "source": [
    "# Get the historic record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4000774",
   "metadata": {},
   "source": [
    "### Search ERA metadata from catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb31423",
   "metadata": {},
   "source": [
    "#### Now we use the store from the ux testing file to actually get the desired attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bcd3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r host\n",
    "credentials = boto3.Session().get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, my_region)\n",
    "index_name = 'era5-pds'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da623e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearch_client = OpenSearch(\n",
    "        hosts = [{'host': host, 'port': 443}],\n",
    "        http_auth = auth,\n",
    "        use_ssl = True,\n",
    "        verify_certs = True,\n",
    "        connection_class = RequestsHttpConnection\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ab4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def query_nc(q, index_name):\n",
    "    \n",
    "    queryy = {\n",
    "      'size': 1,\n",
    "      'query': {\n",
    "        'multi_match': {\n",
    "          'query': q,\n",
    "            'fields': ['fileName']\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    respons = opensearch_client.search(\n",
    "        body = queryy,\n",
    "        index = index_name\n",
    "    )\n",
    "    \n",
    "    res = [i['_source']['fileName'] for i in respons['hits']['hits']][0]\n",
    "    d_pool = [d['_source']['dask_pool'] for d in respons['hits']['hits']]\n",
    "    regio = [f['_source']['region'] for f in respons['hits']['hits']]\n",
    "    regio = list(set(regio))[0]\n",
    "    d_pool = list(set(d_pool))[0]\n",
    "    return res, regio, d_pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196f4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "%store -r start_date end_date\n",
    "\n",
    "start_year = int(start_date.year) #really want this to be 2010\n",
    "end_year = int(end_date.year)\n",
    "\n",
    "lustre_mount_point = \"/fsx\"\n",
    "years = list(np.arange(start_year, end_year+1, 1))\n",
    "\n",
    "# todo: update how we handle this\n",
    "months = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f95f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r desired_attribute\n",
    "attr1 = desired_attribute\n",
    "attr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r start_date\n",
    "start_date.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = []\n",
    "from dateutil.relativedelta import relativedelta\n",
    "current_date = start_date\n",
    "\n",
    "while current_date <= end_date:\n",
    "#     print(current_date.month)\n",
    "#     datem = datetime.datetime.strptime(datetime.datetime.strftime(current_date, \"%Y-%M-%d\"), \"%Y-%m-%d\")\n",
    "    current_month = str(current_date.month)\n",
    "    if len(current_month) == 1:\n",
    "        current_month = \"0\" + current_month\n",
    "    item = '{}/{}/{}/{}/{}.nc'.format(index_name, current_date.year, current_month, 'data',attr1)\n",
    "#     print(item)\n",
    "    n_list.append(item)\n",
    "    current_date = current_date + relativedelta(months=1)\n",
    "# n_list2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dask_pool = []\n",
    "region = []\n",
    "nc_list = []\n",
    "\n",
    "for nc in n_list:\n",
    "    fileName, regn, dask_pool = query_nc(nc, index_name)\n",
    "    nc_list.append(fileName)\n",
    "    region_dask_pool.append(dask_pool)\n",
    "    region.append(regn)\n",
    "\n",
    "region = list(set(region))[0]\n",
    "region_dask_pool = list(set(region_dask_pool))[0]\n",
    "print(nc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eafbe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_pool_region = 'us-east-1'\n",
    "%store historical_pool_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c27ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with pool(historical_pool_region):\n",
    "    historical_data = xr.open_mfdataset(nc_list, engine='h5netcdf', concat_dim='time0', combine='nested', coords='minimal', compat='override', parallel=True, chunks={'lon':200,'lat':200,'time0':720})\n",
    "    %store historical_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
